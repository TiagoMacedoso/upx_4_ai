{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "verbose = True\n",
    "\n",
    "image = cv2.imread('/mnt/estudo_tiago/upx_4_ai/bases_estudo/12 - Deteccao de placas e Pytesseract/2.jpg')\n",
    "\n",
    "image = imutils.resize(image, width=500)\n",
    "\n",
    "if verbose == True:\n",
    "    cv2.imshow(\"Imagem original\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "if verbose == True:\n",
    "    cv2.imshow(\"Imagem cinza\", gray)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "gray = cv2.bilateralFilter(gray, 11,17,17)\n",
    "\n",
    "if verbose == True:\n",
    "    cv2.imshow(\"Imagem filtrada\", gray)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "edged = cv2.Canny(gray, 170, 200)\n",
    "\n",
    "if verbose == True:\n",
    "    cv2.imshow(\"Imagem com canny\", edged)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "cnts, _, = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img1 = image.copy()\n",
    "cv2.drawContours(img1, cnts, -1, (0,255,0), 3)\n",
    "\n",
    "if verbose == True:\n",
    "    cv2.imshow(\"Imagem contornos\", img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse=True)[:30]\n",
    "NumPlacaCnt = None\n",
    "\n",
    "img2 = image.copy()\n",
    "cv2.drawContours(img2, cnts, -1, (0, 255, 0),3)\n",
    "\n",
    "if verbose == True:\n",
    "    cv2.imshow(\"Imagem TOP 30\", img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "count = 0\n",
    "idx = 1\n",
    "\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02*peri, True)\n",
    "    if len(approx) == 4:\n",
    "        NumPlacaCnt = approx\n",
    "        \n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        new_img = gray[y:y+h, x:x+w]\n",
    "        cv2.imwrite('Placa' + str(idx) + '.png', new_img)\n",
    "        break\n",
    "    \n",
    "cv2.drawContours(image, [NumPlacaCnt], -1, (0,255,0), 3)\n",
    "\n",
    "if verbose == True:\n",
    "    cv2.imshow(\"Imagem final com placa detectada\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "Cropped_img_loc = 'Placa', str(idx), + '.png'\n",
    "\n",
    "if verbose == True:\n",
    "    cv2.imshow(\"Imagem cropped placa\", cv2.imread(Cropped_img_loc))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/share/doc/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face com blur para LGPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "    \n",
    "cascade = cv2.CascadeClassifier('/mnt/estudo_tiago/upx_4_ai/bases_estudo/11 - Faces/Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def faceBlur(gray, frame):\n",
    "    faces = cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    for(x,y,w,h) in faces:\n",
    "        roi_faces = frame[y:y+h, x:x+w]\n",
    "        blur = cv2.GaussianBlur(roi_faces, (101,101), 0)\n",
    "        frame[y:y+h, x:x+w] = blur\n",
    "    \n",
    "    return frame\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = faceBlur(gray, frame)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Landmarks em faces humanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "p = '/mnt/estudo_tiago/upx_4_ai/bases_estudo/11 - Faces/shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        for j in range(1,68):\n",
    "            cv2.putText(frame, str(j), (shape.part(j).x, shape.part(j).y), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.3, color=(0,0,255))\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador de Haar (Detecção de Faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./bases_estudo/11 - Faces/Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2. rectangle(frame, (x, y), (x+w, y+h), (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "    \n",
    "    cv2.imshow('Faces detectadas', frame)\n",
    "    \n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferenciação de frames - Fluxo Ótico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "mask = np.zeros_like(first_frame)\n",
    "\n",
    "mask[..., 1] = 255\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, pyr_scale=0.5, levels=3, winsize=15, iterations=3, poly_n=5, poly_sigma=1.1, flags=0)\n",
    "    \n",
    "    #computar a magnitude e and do optical flow dos vetores 2D\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    #print(magnitude)\n",
    "    #print(angle)\n",
    "    \n",
    "    #Setar o hue de acordo com o fluxo optico\n",
    "    mask[..., 0] = angle * 180 /np.pi/2\n",
    "    \n",
    "    #setar a imagem de acordo com a magnitude de fluxo optico (normalizado)\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    #converter HSV para BGR\n",
    "    rgb = cv2. cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    #soma ponderada\n",
    "    dense_flow = cv2.addWeighted(frame, 1, rgb, 2, 0)\n",
    "    \n",
    "    cv2.imshow(\"Dense optical flow\", dense_flow)\n",
    "    prev_gray = gray\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord ('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferenciação de frame com MOG2 e KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mog = cv2.createBackgroundSubtractorMOG2(history=300, varThreshold=10, detectShadows=True)\n",
    "knn = cv2.createBackgroundSubtractorKNN(history=100, dist2Threshold=40, detectShadows=True)\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    fgmask1 = mog.apply(frame)\n",
    "    fgmask2 = knn.apply(frame)\n",
    "    \n",
    "    cv2.imshow('MOG2', fgmask1)\n",
    "    cv2.imshow('KNN', fgmask2)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame Diff (Diferenciação de frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "prox_frame = frame\n",
    "\n",
    "while True:\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    prox_frame_gray = cv2.cvtColor(prox_frame, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    frame_diff = cv2.absdiff(frame_gray, prox_frame_gray)\n",
    "    \n",
    "    cv2.imshow('frame diff', frame_diff)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    prox_frame = frame.copy()\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI - Área de interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#imagem de teste\n",
    "image = cv2.imread('teste_roi.png')\n",
    "image_to_show = np.copy(image)\n",
    "\n",
    "#etados iniciais do mouse\n",
    "cropping = False\n",
    "x_init, y_init, top_left_pt, bottom_right_pt = 0, 0, 0, 0\n",
    "\n",
    "def roi(event, x, y, flags, param):\n",
    "    global image_to_show, x_init, y_init, top_left_pt, bottom_right_pt, cropping\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cropping = True\n",
    "        x_init, y_init = x, y\n",
    "        image_to_show = np.copy(image)\n",
    "        print(f'Ponto inicial em X {x_init}')\n",
    "        print(f'Ponto inicial em Y {y_init}')\n",
    "        \n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if cropping == True:\n",
    "            image_to_show = np.copy(image)\n",
    "            cv2.rectangle(image_to_show, (x_init, y_init),\n",
    "                          (x, y), (0, 255, 0), 1)\n",
    "            \n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        cropping = False\n",
    "        top_left_pt, bottom_right_pt = x, y\n",
    "        print(f'Ponto superior {top_left_pt}')\n",
    "        print(f'Ponto inferior {bottom_right_pt}')\n",
    "        \n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', roi)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('image', image_to_show)\n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "    if k == ord('c'):\n",
    "        if y_init > bottom_right_pt:\n",
    "            y_init, bottom_right_pt = bottom_right_pt, y_init\n",
    "        if x_init > top_left_pt:\n",
    "            x_init, top_left_pt = top_left_pt, x_init\n",
    "            \n",
    "        if bottom_right_pt - y_init > 1 and top_left_pt - x_init > 0:\n",
    "            image = image[y_init:bottom_right_pt, x_init:top_left_pt]\n",
    "            print(image)\n",
    "            image_to_show = np.copy(image)\n",
    "\n",
    "    if k == ord('s'):\n",
    "        cv2.imwrite('teste.jpg', image_to_show)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retângulos nas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#callback\n",
    "def draw_rect(event, x, y, flags, params):\n",
    "    global pt1, pt2, topLeftClicked, bottomRightClicked\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if topLeftClicked == True and bottomRightClicked == True:\n",
    "            pt1 = (0,0)\n",
    "            pt2 = (0,0)\n",
    "            topLeftClicked = False\n",
    "            bottomRightClicked = False\n",
    "        \n",
    "        if topLeftClicked == False:\n",
    "            pt1 = (x, y)\n",
    "            topLeftClicked = True\n",
    "        elif bottomRightClicked == False:\n",
    "            pt2 = (x,y)\n",
    "            bottomRightClicked = True\n",
    "            \n",
    "\n",
    "#variaveis globais\n",
    "pt1 = (0,0)\n",
    "pt2 = (0,0)\n",
    "topLeftClicked = False\n",
    "bottomRightClicked = False\n",
    "\n",
    "cv2.namedWindow('teste')\n",
    "cv2.setMouseCallback('teste', draw_rect)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    # desenhar retangulo\n",
    "    if topLeftClicked:\n",
    "        cv2.circle(frame, center=pt1, radius=5, color=(0,0,255))\n",
    "    if topLeftClicked and bottomRightClicked:\n",
    "        cv2.rectangle(frame, pt1, pt2, color=(0,0,255), thickness=1)\n",
    "    \n",
    "    cv2.imshow('teste', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\"\"\" width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#parte superior\n",
    "x = width // 2\n",
    "y = height // 2\n",
    "\n",
    "#Altura \n",
    "\n",
    "w = width // 4\n",
    "h = height // 4\n",
    "\n",
    "#Exibir\n",
    " \"\"\"\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    \"\"\" cv2.rectangle(frame, (x,y), (w+x, y+h), color=(0,0,255), thickness=4) \"\"\"\n",
    "    \n",
    "    cv2.imshow('video', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acessando meu vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture('/mnt/tiago-estudo/upx_4_ai/video1.mp4')\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print(\"ERROR!\")\n",
    "    \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        time.sleep(1/5)\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acessar web cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
